{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobility Basket of Products \n",
    "##  Yearly Average Citizen Intensity Consumption calculation per country.\n",
    "\n",
    "As a first step to estimate european citizens consumption footprint by country using Life Cycle Assessment (LCA) it is necessary to calculate the consumption intensity of the representative products considered (in general those bearing most of the env. impacts) groupped into Baskets of Products (BoP). The present script contains the functions dedicated to the extraction and harmonization of the data on the Mobility BoP products and the calculation of the corresponding consumption intensities.\n",
    "\n",
    "The three data sources used in this case are:\n",
    "\n",
    "- [EC Mobility and Transport Statistical Pocketbook](https://ec.europa.eu/transport/facts-fundings/statistics/pocketbook-2019_en)(PB).\n",
    "- [Eurostat](https://ec.europa.eu/eurostat)(ESTAT).\n",
    "- [Consumer Footprint. Basket of Products indicator on mobility](https://ec.europa.eu/jrc/en/publication/consumer-footprint-basket-products-indicator-mobility) report(Rep.).\n",
    "\n",
    "The specific categories, datasets and tables from each of the sources used here can be found in the [ds_transport](#ds_transport) function.\n",
    "\n",
    "As for the Mobility BoP representative products, what follows is a summary of all the representative products considered:\n",
    "\n",
    "- **Road transport**:\n",
    "  - *Passenger cars*: 16 types classified according to their fuel type, capacity and year of production.\n",
    "  - *Two wheels*: 3 types classified according to their capacity and year of production.\n",
    "  - *Buses*: 3 types lassified according to their weight and year of production.\n",
    "- **Rail transport**: Either diesel or electric.\n",
    "\n",
    "- **Air transport**: intra-EU, extra-EU and international flights.\n",
    " \n",
    "For each of the main transport groups the following data will be retrieved:\n",
    "\n",
    "- *Passenger cars*: million passenger km (PB), type of fuel, engine displacement and technology coefficients (ESTAT) and occupancy factors (Rep.).\n",
    "\n",
    "- *Two wheels*: number of vehicles (ESTAT), number of vehicles (ESTAT), contribution to passenger km and occupancy factor (Rep.). Besides, the number of vehicles per category will be calculated out of the number of vehicles figures.\n",
    "\n",
    "- *Buses*: number of vehicles (ESTAT), number of vehicles (ESTAT) and occupancy factors (Rep.). Besides, the number of vehicles per category will be calculated out of the number of vehicles figures.\n",
    "\n",
    "- **Rail transport**: Millions of trains km (ESTAT), million passenger km (PB) and occupancy factors (Rep.). Besides the share of trains by category is calculated out of the millions of trains km figures.\n",
    "\n",
    "- **Air transport**: Number of passengers (PB) and km per flight (Rep.).\n",
    "\n",
    "In some cases the data retrieved from the original sources is already ready to be used, however in other cases it will have to undergo some modifications before it can be used. A third case would be those additional figures which are calculated out of the originally retrieved data, which are the following for the different transport groups:\n",
    "\n",
    "- *Two wheels*: the number of vehicles per category will be calculated out of the number of vehicles figures.\n",
    "\n",
    "- *Buses*: the number of vehicles per category will be calculated out of the number of vehicles figures.\n",
    "\n",
    "- **Rail transport**: the share of trains by category is calculated out of the millions of trains km figures.\n",
    "\n",
    "The functions in this script will fill out the spaces of a previously created frame table containing only the information about the different transport groups and subgroups names with the retrieved, modified and calcuated figures under the corresponding column. In that table the names of the columns are short forms of the original name (e.g. *tech_coeff* for technology coefficients) and its correspondance with the actual figure name can be found wihtin the [ds_transport](#ds_transport) function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages\n",
    "\n",
    "In addition to Python 3.3 built-in packages and some other specific packages, such as the [*eurostat*](https://pypi.org/project/eurostat/) package, two previously developed scripts, *data_inputs* and *predownload* will have to be loaded too. In order to simplify the loading it is recommended to copy both of the into the current working dictionary, i.e. where the present script is located. Finally, within that same directory, a *input* folder has to be created and the pocketbook (e.g. *pb2019-section23.xls*) as well as the previously mentioned frame table (*mob_frame.xlsx*) copied inside it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from itertools import compress\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import eurostat as estat\n",
    "import math\n",
    "from scipy import interpolate\n",
    "\n",
    "# Our scripts\n",
    "\n",
    "import data_inputs as di\n",
    "import predownload as predw\n",
    "\n",
    "# Folders\n",
    "\n",
    "INPUTS = \"../inputs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the mobility frame where the data will be integrated:\n",
    "mob_file = 'mob_frame.xlsx'\n",
    "file_path = os.path.join(INPUTS, mob_file)\n",
    "mob_frame = pd.read_excel(file_path)\n",
    "\n",
    "# Selecting the years interval and countries of interest:\n",
    "start_year = '2010'\n",
    "end_year = '2018'\n",
    "countries_names = ['Austria']\n",
    "\n",
    "# loading the Pocketbook:\n",
    "file_name = 'pb2019-section23.xls'\n",
    "\n",
    "# Running the Mobility function:\n",
    "m = mobility(mob_frame, start_year, end_year, countries_names, file_name, INPUTS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ds_transport'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_transport(DS, col_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    For the different data sets, it provides information about the way they have to be filtered, the units conversion they require,\n",
    "    how they should me merged with the mobility frame, in which column will their information be displayed etc etc\n",
    "    \n",
    "    :param DS : data set name (EUROSTAT), sheetname (POCKETBOOK) or BoP report sheet.\n",
    "    :type DS : str.\n",
    "    :param col_name : name of the dictionary required.\n",
    "    :type col_name : str.\n",
    "    :return :  the information required, being it the units conversion factor, the filtering values etc.\n",
    "    :rtype : list/dict.\n",
    "    \n",
    "    \"\"\"\n",
    "    # In each data set the values of interst for certain categories. I.e for \"road_eqs_mopeds\" only the rows for which\n",
    "    # \"mot_nrg\" = \"TOTAL\" and \"vehicle\" = \"MOP\" will be kept. {} means no filter will be applied.\n",
    "    \n",
    "    filters_dict = {\"road_eqs_carage\":{},\n",
    "                    \"road_eqs_mopeds\":{'mot_nrg':[\"TOTAL\"], 'vehicle':[\"MOP\"]},\n",
    "                    \"road_eqs_motorc\":{},\n",
    "                    \"bus_coach\":{},\n",
    "                    \"road_eqs_busmot\":{},\n",
    "                    \"rail_tf_traveh\":{'train':[\"TOTAL\"]},\n",
    "                    \"road_tf_road\":{\"vehicle\":[\"BUS_MCO\"]},\n",
    "                    \"avia_panc\":{'tra_meas':['PAS_BRD'], 'unit':[\"PAS\"]},\n",
    "                    \"avia_paincc\":{'tra_meas':['PAS_BRD_DEP'], 'unit':[\"PAS\"], \"partner\" : [\"EU28\"]},\n",
    "                    \"avia_paexcc\":{'tra_meas':['PAS_BRD_DEP'], 'unit':[\"PAS\"], \"partner\" : [\"EXT_EU\"]},\n",
    "                    \"road_pa_mov\":{},\n",
    "                    \"road_eqs_carpda\":{},\n",
    "                    \"road_eqs_carmot\":{},\n",
    "                     \"cars\":{},\n",
    "                     \"rail_pkm\":{},\n",
    "                     \"bop121\" : {}, \n",
    "                     \"bop142\" : {},\n",
    "                     \"bop143_148\" : {},\n",
    "                   }\n",
    "    \n",
    "    # In order to merge the data extracted from the data sets with the mobility frame, the function \"merge\" has to\n",
    "    # be provided from both sides the columns it has to try to match. For instance, for \"road_eqs_carage\", the function merge will have to match\n",
    "    # the values in mobility column \"id_1\" with those in column \"age_type\" in the data extracted from \"road_eqs_carage\".\n",
    "     \n",
    "    \n",
    "    sort_dict = {\"road_eqs_carage\":{\"id_1\":\"age_type\", \"year\" : \"year\", \"geo\\\\time\" : \"geo\\\\time\"},\n",
    "                  \"road_eqs_mopeds\":{\"id_1\":'vehicle', \"year\" : \"year\", \"geo\\\\time\" : \"geo\\\\time\"},\n",
    "                    \"road_eqs_motorc\":{\"id_1\":\"engine\", \"year\" : \"year\", \"geo\\\\time\" : \"geo\\\\time\"},\n",
    "                     \"bus_coach\":{\"vehicle_type\":\"vehicle\", \"year\" : \"year\", \"geo\\\\time\" : \"geo\\\\time\"},\n",
    "                    \"road_eqs_busmot\":{\"id_1\":\"mot_nrg\", \"year\" : \"year\", \"geo\\\\time\" : \"geo\\\\time\"},\n",
    "                    \"rail_tf_traveh\":{\"id_1\":'vehicle', \"year\" : \"year\", \"geo\\\\time\" : \"geo\\\\time\"},\n",
    "                    \"road_tf_road\":{\"id_2\":'tra_infr', \"year\" : \"year\", \"geo\\\\time\" : \"geo\\\\time\"},\n",
    "                    \"avia_panc\":{\"id_1\":\"tra_meas\", \"type\" : \"flight_type\", \"year\" : \"year\", \"geo\\\\time\" : \"geo\\\\time\"},\n",
    "                    \"avia_paincc\":{\"id_1\":\"tra_meas\", \"type\" : \"flight_type\", \"year\" : \"year\", \"geo\\\\time\" : \"geo\\\\time\"},\n",
    "                    \"avia_paexcc\":{\"id_1\":\"tra_meas\", \"type\" : \"flight_type\", \"year\" : \"year\", \"geo\\\\time\" : \"geo\\\\time\"},\n",
    "                    \"road_pa_mov\":{\"id_2\":'vehicle', \"year\" : \"year\", \"geo\\\\time\" : \"geo\\\\time\"},\n",
    "                    \"road_eqs_carpda\":{\"id_3\":'mot_nrg', \"year\" : \"year\", \"geo\\\\time\" : \"geo\\\\time\"},\n",
    "                    \"road_eqs_carmot\":{\"id_2\":'engine', \"id_3\":'mot_nrg', \"year\" : \"year\", \"geo\\\\time\" : \"geo\\\\time\"},\n",
    "                     \"cars\":{\"vehicle_type\" : \"vehicle\", \"year\" : \"year\", \"geo\\\\time\" : \"geo\\\\time\"},\n",
    "                     \"rail_pkm\":{\"vehicle_type\" : \"vehicle\", \"year\" : \"year\", \"geo\\\\time\" : \"geo\\\\time\"},\n",
    "                     \"bop121\" : {\"type\" : \"flight_type\", \"year\" : \"year\", \"geo\\\\time\" : \"geo\\\\time\"}, \n",
    "                     \"bop142\" : {\"vehicle_type\" : \"vehicle\", \"year\" : \"year\", \"geo\\\\time\" : \"geo\\\\time\"},\n",
    "                     \"bop143_148\" : {\"vehicle_type\" : \"vehicle\", \"year\" : \"year\", \"geo\\\\time\" : \"geo\\\\time\"},\n",
    "\n",
    "                }\n",
    "    \n",
    "    # Columns to be added to the data frames extracted from the different data sets.\n",
    "    \n",
    "    add_col_dict = {\"road_eqs_carage\":{},\n",
    "                  \"road_eqs_mopeds\":{},\n",
    "                    \"road_eqs_motorc\":{},\n",
    "                    \"road_eqs_busmot\":{},\n",
    "                    \"rail_tf_traveh\":{},\n",
    "                    \"road_tf_road\":{},\n",
    "                    \"avia_panc\":{\"flight_type\" : \"national\"},\n",
    "                    \"avia_paincc\":{\"flight_type\" : \"intra_eu\"},\n",
    "                    \"avia_paexcc\":{\"flight_type\" : \"extra_eu\"},\n",
    "                    \"road_pa_mov\":{},\n",
    "                    \"road_eqs_carpda\":{},\n",
    "                    \"road_eqs_carmot\":{},\n",
    "                    \"cars\":{},\n",
    "                    \"rail_pkm\":{},\n",
    "                    \"bop121\" : {},\n",
    "                    \"bop142\" : {},\n",
    "                    \"bop143_148\" : {}}\n",
    "    \n",
    "    # The factor the information retrieved from each of the data sets has to be multiplied for.\n",
    "    \n",
    "    units_dict = {\"road_eqs_carage\":1,\n",
    "                  \"road_eqs_mopeds\":1,\n",
    "                    \"road_eqs_motorc\":1,\n",
    "                    \"road_eqs_busmot\":1,\n",
    "                    \"bus_coach\":1000000000,\n",
    "                    \"rail_tf_traveh\":0.001,\n",
    "                    \"road_tf_road\":1,\n",
    "                    \"avia_panc\":1,\n",
    "                    \"avia_paincc\":1,\n",
    "                    \"avia_paexcc\":1,\n",
    "                    \"road_pa_mov\":1000000,\n",
    "                    \"road_eqs_carpda\":1,\n",
    "                    \"road_eqs_carmot\":1,\n",
    "                    \"cars\":1000000000,\n",
    "                    \"rail_pkm\":1000000000,\n",
    "                    \"bop121\" : 1,\n",
    "                    \"bop142\" : 1,\n",
    "                    \"bop143_148\" : 1\n",
    "                 }\n",
    "    \n",
    "    # The names of the different columns have been shortened, the correspondency would be as follows:\n",
    "    # Number of vehicles : num_vehi, Share of number of vehicles per category : num_vehi_share, Millions of trains : trkm, \n",
    "    # Share of trains km per each category : trkm_share, Number of passengers : num_p, Km per flight : flight_km,\n",
    "    # Contribution to passenger km : contr_pkm, Million passenger km : mill_pkm, Coeff. type of fuel : fuel_coeff, \n",
    "    # Coeff.engine displacement : eng_coeff, Coeff.technology : tech_coeff, Occupancy factor : ocp_factor.\n",
    "    \n",
    "    col_name_dict = {\"road_eqs_carage\" : \"tech_coeff\",\n",
    "                     \"road_eqs_carmot\" : \"eng_coeff\",\n",
    "                     \"road_eqs_carpda\" : \"fuel_coeff\",\n",
    "                     \"road_pa_mov\" : \"mill_pkm\",\n",
    "                     \"bus_coach\" : \"mill_pkm\",\n",
    "                     \"cars\" : \"mill_pkm\",\n",
    "                     \"rail_pkm\" : \"mill_pkm\",\n",
    "                     \"bop143_148\" : \"ocp_factor\",\n",
    "                     \"bop142\" : \"contr_pkm\",\n",
    "                     \"bop121\" : \"flight_km\",\n",
    "                     \"avia_panc\" : \"num_p\",\n",
    "                     \"avia_paincc\" : \"num_p\",\n",
    "                     \"avia_paexcc\" : \"num_p\",\n",
    "                     \"rail_tf_traveh\" : \"trkm\",\n",
    "                     \"road_eqs_busmot\" : \"num_vehi\",\n",
    "                     \"road_tf_road\" : \"mill_vehikm\",\n",
    "                     \"road_eqs_motorc\" : \"num_vehi\",\n",
    "                     \"road_eqs_mopeds\" : \"num_vehi\"}\n",
    "                     \n",
    "                 \n",
    "    # Classification of the different data sets according to their source.\n",
    "    \n",
    "    source_dict = {\"road_eqs_carage\" : \"ESTAT\",\n",
    "                     \"road_eqs_carmot\" : \"ESTAT\",\n",
    "                     \"road_eqs_carpda\" : \"ESTAT\",\n",
    "                     \"road_pa_mov\" : \"ESTAT\",\n",
    "                     \"bus_coach\" : \"POCKETBOOK\",\n",
    "                     \"cars\" : \"POCKETBOOK\",\n",
    "                     \"rail_pkm\" : \"POCKETBOOK\",\n",
    "                     \"bop143_148\" : \"BOP\",\n",
    "                     \"bop142\" : \"BOP\",\n",
    "                     \"bop121\" : \"BOP\",\n",
    "                     \"avia_panc\" : \"ESTAT\",\n",
    "                     \"avia_paincc\" : \"ESTAT\",\n",
    "                     \"avia_paexcc\" : \"ESTAT\",\n",
    "                     \"rail_tf_traveh\" : \"ESTAT\",\n",
    "                     \"road_eqs_busmot\" : \"ESTAT\",\n",
    "                     \"road_tf_road\" : \"ESTAT\",\n",
    "                     \"road_eqs_motorc\" : \"ESTAT\",\n",
    "                     \"road_eqs_mopeds\" : \"ESTAT\"}\n",
    "                    \n",
    "                  \n",
    "                 \n",
    "    # The correspondency between the columns in the final mobility table with the data sets the information displayed in them comes from.\n",
    "    # For instance, the information that will be displayed in column \"tech_coeff\" will come from \"road_eqs_carage\".\n",
    "    \n",
    "    merge_dict = {\"tech_coeff\" : [\"road_eqs_carage\"],\n",
    "                  \"eng_coeff\" : [\"road_eqs_carmot\"],\n",
    "                  \"fuel_coeff\" : [\"road_eqs_carpda\"],\n",
    "                  \"mill_pkm\" : [\"road_pa_mov\", \"cars\", \"rail_pkm\", \"bus_coach\"],\n",
    "                  \"ocp_factor\" : [\"bop143_148\"],\n",
    "                  \"contr_pkm\" : [\"bop142\"],\n",
    "                  \"flight_km\" : [\"bop121\"], \n",
    "                  \"num_p\" : [\"avia_panc\", \"avia_paincc\", \"avia_paexcc\"],\n",
    "                  \"trkm\" : [\"rail_tf_traveh\"],\n",
    "                  \"num_vehi\" : [\"road_eqs_busmot\", \"road_eqs_motorc\", \"road_eqs_mopeds\"],\n",
    "                  \"mill_vehikm\" : [\"road_tf_road\"]}\n",
    "    \n",
    "    # In some cases, some categories/columns of some data sets require the addition of new elements. \n",
    "\n",
    "    extra_types = {\"road_eqs_busmot\" : {\"mot_nrg\" :[\"PET;LPG;DIE;ELC;ALT;DIE_X_HYB;ELC_DIE_HYB;ELC_DIE_PI;HYD_FCELL;OTH\", \"CNG;LNG\"]},\n",
    "                  \"road_tf_road\" : {'tra_infr' : [\"RD_INB;RD_OUTB;RD_OTH\"]},\n",
    "                  \"road_eqs_carage\" : {},\n",
    "                  \"road_eqs_carmot\" : {},\n",
    "                   \"road_eqs_carpda\" : {},\n",
    "                     \"road_pa_mov\" : {},\n",
    "                     \"cars\" : {},\n",
    "                     \"rail_pkm\" : {},\n",
    "                     \"bop143_148\" : {},\n",
    "                     \"bop142\" : {},\n",
    "                     \"bop121\" : {},\n",
    "                     \"avia_panc\" : {},\n",
    "                     \"avia_paincc\" : {},\n",
    "                     \"avia_paexcc\" : {},\n",
    "                     \"rail_tf_traveh\" : {\"vehicle\" : [\"RCA_ELC;LOC_ELC\", \"RCA_DIE;LOC_DIE\"]},\n",
    "                     \"road_eqs_motorc\" : {},\n",
    "                     \"road_eqs_mopeds\" : {}}\n",
    "                 \n",
    "\n",
    "    # Therse are the names to be provided as argument to the function in order to obtain each of the dictionaries.\n",
    "    \n",
    "    col_dicts = {\"FILTERS\" : filters_dict, \"SORT\" : sort_dict, \"UNITS\" : units_dict, \"COLNAMES\" : col_name_dict,\n",
    "                 \"MERGE\" : merge_dict, \"SOURCE\" : source_dict, \"EXTRA\" : extra_types, \"ADDCOL\" : add_col_dict}\n",
    "    \n",
    "    if (col_name == \"MERGE\"):\n",
    "        \n",
    "        return(col_dicts[col_name])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        return(col_dicts[col_name][DS])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bop_report(bop_sheet, col_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    Provide the information contained in the tables on pag.143,148,121 and 142 of the BoP Mobility report.\n",
    "    \n",
    "    :param bop_sheet : BoP mobility report sheet name.\n",
    "    :type bop_sheet : str.\n",
    "    :param col_name : reference to the information required within the sheet.\n",
    "    :type col_name : str.\n",
    "    :return : information required.\n",
    "    :rtype : list/dict.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    bop_table_dict = {\"bop143_148\" : {\"vehicle\" : [\"Passenger_Cars\", \"2W\", \"Buses\"], \"value\" : [1.62, 1.1, 14.7]},\n",
    "                     \"bop121\" : {\"flight_type\" : [\"national\", \"intra_eu\", \"extra_eu\"], \"value\" : [np.nan ,1188, 6287]},\n",
    "                      \"bop142\" : {\"vehicle\" : [\"2W\"], \"value\" : [0.026]}\n",
    "                     }\n",
    "    \n",
    "    bop121_national ={'AT':245, 'BE':148, 'BG':282, 'CY':81, 'CZ':238, 'DE':506, 'DK':175, 'EE':180, 'EL':307, 'ES':1804, 'FI':492,\n",
    " 'FR':677, 'HU':258, 'IE':246, 'IT':465, 'LT':216,'LU':43, 'LV':215, 'MT':50, 'NL':172, 'PL':473, \"UK\":418, 'PT':899, 'RO':413, 'SE':568,\n",
    "                      'SI':120, 'SK':187}\n",
    "    \n",
    "    # Therse are the names to be provided as argument to the function in order to obtain each of the dictionaries.\n",
    "    \n",
    "    col_dicts = {\"BOP_TABLE\" : bop_table_dict, \"BOP_NAT_FLIGHTS\" : bop121_national}\n",
    "    \n",
    "    if col_name == \"BOP_NAT_FLIGHTS\":\n",
    "        \n",
    "        return(col_dicts[col_name])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        return(col_dicts[col_name][bop_sheet])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_countries(countries_names):\n",
    "    \n",
    "    \"\"\"\n",
    "    Check whether the country names are in a given dict, whether they are repeated and turn the country names into country codes.\n",
    "    \n",
    "    :param countries_names : countries names.\n",
    "    :type countries_names : list.\n",
    "    :return : countries in the provided list that belong to the given dict and that are not repeated.\n",
    "    :rtype : list.\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    countries_dict = {'AT': 'Austria', 'BE': 'Belgium', 'BG': 'Bulgaria',\n",
    " 'CY': 'Cyprus', 'CZ': 'Czechia', 'DE': 'Germany', 'DK': 'Denmark', 'EE': 'Estonia', 'EL': 'Greece', 'ES': 'Spain', 'FI': 'Finland',\n",
    " 'FR': 'France', 'HR': 'Croatia', 'HU': 'Hungary', 'IE': 'Ireland', 'IT': 'Italy', 'LT': 'Lithuania','LU': 'Luxemburg', 'LV': 'Latvia',\n",
    "    'MT': 'Malta', 'NL': 'Netherlands', 'PL': 'Poland', \"UK\" : \"United Kingdom\", 'PT': 'Portugal', 'RO': 'Romania', 'SE': 'Sweden', 'SI': 'Slovenia', 'SK': 'Slovakia',\n",
    "               'LI' : 'Liechtenstein', \"TR\" : \"Turkey\", \"XK\" : \"Kosovo\", \"NO\" : \"Norway\", \"MK\" : \"North Macedonia\", \"CH\" : \"Switzerland\", \"EU-28\" : \"EUROPEAN UNION (28)\"\n",
    "               , \"ME\" : \"Montenegro\", \"IS\" : \"Iceland\", \"RS\" : \"Serbia\", \"AL\" : \"Albania\", \"TOTAL\" : \"Total\"}\n",
    "                \n",
    "    countries_list = list(countries_dict.values())\n",
    "    \n",
    "    countries_dict_inverse = {v: k for k, v in countries_dict.items()}\n",
    "    \n",
    "    countries_repeated = predw.check_repeated(countries_names)\n",
    "    \n",
    "    countries_not_in_ds = predw.check_belong(countries_names, countries_list)\n",
    "    \n",
    "    countries_codes = [countries_dict_inverse[c] for c in countries_names if c not in countries_not_in_ds]\n",
    "    \n",
    "    return(countries_codes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_col(input_df, DS):\n",
    "    \n",
    "    \"\"\"\n",
    "    Add a column to the data frame containing the information extracted from a data set.\n",
    "    \n",
    "    :param input_df : data extracted from a data set.\n",
    "    :type input_df : data frame.\n",
    "    :param DS : data set the information in input_df has been extracted from.\n",
    "    :type DS : str.\n",
    "    :return :  data originally extracted plus the information in the new column.\n",
    "    :rtype : data frame.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    add_col_dict = ds_transport(DS, \"ADDCOL\")\n",
    "    \n",
    "    if add_col_dict == {}:\n",
    "        \n",
    "        return(input_df)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        col = list(add_col_dict.keys())[0]\n",
    "        \n",
    "        value = add_col_dict[col]\n",
    "        \n",
    "        input_df[col] = value\n",
    "        \n",
    "        return(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_extra_type(input_df, DS):\n",
    "    \n",
    "    \"\"\"\n",
    "    Add new categories/types/elements in a column to the given data frame containing the information extracted from a data set.\n",
    "    \n",
    "    :param input_df : data extracted from a data set.\n",
    "    :type input_df : data frame.\n",
    "    :param DS : data set the information in input_df has been extracted from.\n",
    "    :type DS : str.\n",
    "    :return :  data originally extracted plus the new categories/types/elements in a column.\n",
    "    :rtype : data frame.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    if ds_transport(DS, \"EXTRA\") == {} or input_df.empty :\n",
    "        \n",
    "        return(input_df)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        extra_type_dict = ds_transport(DS, \"EXTRA\")\n",
    "        \n",
    "        ext_type_col = list(extra_type_dict.keys())[0]\n",
    "        \n",
    "        types_in_col = list(set(input_df[ext_type_col].tolist()))\n",
    "        \n",
    "        extra_types = extra_type_dict[ext_type_col]\n",
    "        \n",
    "        values_col = ds_transport(DS, \"COLNAMES\")\n",
    "        \n",
    "        possible_values = list(set(input_df[ext_type_col].tolist())) + extra_types\n",
    "        \n",
    "        input_df = input_df.pivot_table(values = values_col, index =  [\"year\", \"geo\\\\time\", \"unit\"], columns = ext_type_col, dropna = False).reset_index()\n",
    "        \n",
    "        for e_type in extra_types:\n",
    "        \n",
    "            e_types_list = e_type.split(\";\")\n",
    "                     \n",
    "            e_types_list = [t for t in e_types_list if t in types_in_col]\n",
    "        \n",
    "            input_df[e_type] = input_df[e_types_list].sum(axis = 1)\n",
    "            \n",
    "        id_cols = [col for col in input_df.columns if col not in possible_values]\n",
    "            \n",
    "        input_df = pd.melt(input_df, id_vars = id_cols, value_vars = possible_values)\n",
    "        \n",
    "        input_df.rename(columns = {\"value\" : values_col}, inplace  = True)\n",
    "        \n",
    "        return(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mobility(start_year, end_year, countries_names, DS):\n",
    "    \n",
    "    \"\"\"Downloads the data from the provided EUROSTAT data set, filters it for the countries and period given and fills up\n",
    "    information gaps.\n",
    "    \n",
    "    :param start_year : first year of the period of interest.\n",
    "    :type start_year : str.\n",
    "    :param end_year : last year of the period of interest.\n",
    "    :type end_year : str.\n",
    "    :param countries_names : names of the countries of interest.\n",
    "    :type countries : list.\n",
    "    :param DS : EUROSTAT data set from which the information is downloaded.\n",
    "    :type DS : str.\n",
    "    :return: data frame containing the information required.\n",
    "    :rtype: data frame.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    data = estat.get_data_df(DS, flags=True)\n",
    "\n",
    "    id_cols = [col for col in data.columns if not col.startswith((\"1\",\"2\"))] # Identity columns.\n",
    "\n",
    "    new_columns = [col.replace(\"_value\", \"\") for col in data.columns]\n",
    "    \n",
    "    new_columns_dict = dict(zip(data.columns, new_columns))\n",
    "    \n",
    "    data = data.rename(columns = new_columns_dict)\n",
    "    \n",
    "    data.columns = [str(c) for c in data.columns]\n",
    "    \n",
    "    # Filter other categories.\n",
    "    \n",
    "    filters_dict = ds_transport(DS, \"FILTERS\")\n",
    "    \n",
    "    if filters_dict != {}:\n",
    "        \n",
    "        for key in filters_dict.keys():\n",
    "            \n",
    "            data = data[data[key].isin(filters_dict[key])]\n",
    "    \n",
    "    # Remove the rows with all the cells empty.\n",
    "    \n",
    "    data = data.set_index(\"geo\\\\time\")\n",
    "    \n",
    "    data = data.dropna(axis = 0, how = \"all\")\n",
    "    \n",
    "    data = data.reset_index()\n",
    "    \n",
    "    # If the data for a particular year is missing it will be extrapolated out of the existing data through a linear regression.\n",
    "    \n",
    "    years = [str(y) for y in list(range(int(start_year), (int(end_year) + 1)))] \n",
    "    \n",
    "    existing_years = [c for c in data.columns if c.isnumeric()]\n",
    "    \n",
    "    years_cols = [yr for yr in years if yr in data.columns]\n",
    "    \n",
    "    def extrapolate(df, nyr):\n",
    "        df = df.dropna()\n",
    "        y = df.tolist()\n",
    "        if len(y)<2:\n",
    "            return(np.nan)\n",
    "        else:\n",
    "            x = df.index.astype(float)\n",
    "            f = interpolate.interp1d(x,y)\n",
    "            # The new elements are chosen to make sure lie within the range of x values.\n",
    "            new_x = [x[0], (x[0]+x[1])/2]\n",
    "            new_y = f(new_x)\n",
    "            m = np.diff(new_y)\n",
    "            b = (sum(new_y)-(m*sum(new_x)))/2\n",
    "            value = m*nyr+b\n",
    "            # The extrapolation may also produce undesired negative values.\n",
    "            if value[0]>0:\n",
    "                return(value[0])\n",
    "            else:\n",
    "                return(np.nan)\n",
    "    \n",
    "    \n",
    "    if len(years_cols) < len(years):\n",
    "        \n",
    "        missing_years = [yr for yr in years if yr not in years_cols]\n",
    "        \n",
    "        print(\"{} not in dataset {}. The values will be extrapolated\".format(missing_years, DS))\n",
    "            \n",
    "        for new_yr in missing_years:\n",
    "        \n",
    "            data[new_yr] = data[existing_years].apply(lambda x: extrapolate(x, int(new_yr)),axis = 1)\n",
    "    \n",
    "    new_cols = id_cols + years\n",
    "    \n",
    "    data = data[new_cols]\n",
    "\n",
    "    # If a country is missing from the data set, a new line will be added for that country with the values for the selected\n",
    "    # years being the average of the corresponding values of the existing countries.\n",
    "    \n",
    "    countries_codes = check_countries(countries_names)\n",
    "    \n",
    "    absent_cc = [cc for cc in countries_codes if cc not in data[\"geo\\\\time\"].tolist()]\n",
    "    \n",
    "    group_cols = [c for c in id_cols if c != \"geo\\\\time\"]\n",
    "    \n",
    "    data_gp = data.groupby(group_cols)\n",
    "    \n",
    "    data_mean = data.groupby(group_cols)[years].mean().reset_index()\n",
    "    \n",
    "    groups = data_gp.groups\n",
    "    \n",
    "    if len(absent_cc)>0:\n",
    "        \n",
    "        print(\"{} data is missing. The countries average will be used to fill the gap\".format(absent_cc))\n",
    "    \n",
    "        for cc in absent_cc:\n",
    "        \n",
    "            data_mean[\"geo\\\\time\"] = cc\n",
    "            \n",
    "            data = data.append(data_mean)\n",
    "            \n",
    "    # If for one country some information is missing (e.g. in \"road_tf_road\") Bulgaria does not have values for \"tra_infr\" = MWAY but it\n",
    "    # does for other \"tra_infr\" values. The corresponding all countries mean value for the particular informartion missing is calculated\n",
    "    # and introduce in the data frame in a new line with \"geo\\\\time\" column equal to the country of interest.\n",
    "\n",
    "    for g in groups:\n",
    "        \n",
    "        data_g = data_gp.get_group(g)\n",
    "        \n",
    "        missing_cc = [ccode for ccode in countries_codes if ccode not in data_g[\"geo\\\\time\"].tolist()]\n",
    "        \n",
    "        for ccode in missing_cc:\n",
    "\n",
    "            data_cc = data_g.groupby(group_cols).mean().reset_index()\n",
    "\n",
    "            data_cc[\"geo\\\\time\"] = ccode\n",
    "            \n",
    "            data = data.append(data_cc)\n",
    "            \n",
    "    \n",
    "    # Fills out nan values in the years columns with the column mean.\n",
    "\n",
    "    data = data.fillna(data.mean())\n",
    "     \n",
    "    # Filters by country.\n",
    "    \n",
    "    data = data[data[\"geo\\\\time\"].isin(countries_codes)]\n",
    "    \n",
    "    # Reorganize data frame.\n",
    "\n",
    "    data = pd.melt(data, id_vars = id_cols, value_vars = years)\n",
    "\n",
    "    # Adapt to right units.\n",
    "    \n",
    "    units_factor = ds_transport(DS, \"UNITS\")\n",
    "    \n",
    "    data[\"value\"] = data[\"value\"] * units_factor\n",
    "    \n",
    "    # Set columns names and data types.\n",
    "    \n",
    "    values_col = ds_transport(DS, \"COLNAMES\")\n",
    "    \n",
    "    data = data.rename(columns = {\"variable\" : \"year\", \"value\" : values_col})\n",
    "    \n",
    "    data.columns = [str(c) for c in data.columns]\n",
    "    \n",
    "    data[\"year\"] = data[\"year\"].astype(str)\n",
    "    \n",
    "    # Add extra types.\n",
    "    \n",
    "    data = add_extra_type(data, DS)\n",
    "    \n",
    "    # Add columns.\n",
    "    \n",
    "    data = add_col(data, DS)\n",
    "    \n",
    "    data = data.replace(0, np.nan)\n",
    "          \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bop(start_year, end_year, countries_names, bop_pag):\n",
    "    \n",
    "    \"\"\"\n",
    "    Extract the information from the table in the BoP Mobility sheet provided for the years and countries given.\n",
    "    \n",
    "    :param start_year : first year of the period of interest.\n",
    "    :type start_year : str.\n",
    "    :param end_year : last year of the period of interest.\n",
    "    :type end_year : str.\n",
    "    :param countries_names : names of the countries of interest.\n",
    "    :type countries : list.\n",
    "    :param bop_pag : BoP Mobility sheet containing the table with the information.\n",
    "    :type bop_pag : str.\n",
    "    :return: data frame containing the information required.\n",
    "    :rtype: data frame.\n",
    "    \n",
    "    NOTE: Since the information in the BoP Mobility report tables is the same for every year, here the start and end years\n",
    "    will be use to add a column \"year\" to the resulting data frame instead of for filtering information.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    years = [str(yr) for yr in list(range(int(start_year), int(end_year) +1 ))]\n",
    "    \n",
    "    countries_codes = check_countries(countries_names)\n",
    "    \n",
    "    value_col = ds_transport(bop_pag, \"COLNAMES\")\n",
    "    \n",
    "    bop_dict = bop_report(bop_pag, \"BOP_TABLE\")\n",
    "    \n",
    "    bop_nat_flights = bop_report(\"\", \"BOP_NAT_FLIGHTS\")\n",
    "    \n",
    "    all_c_yr = []\n",
    "\n",
    "    for yr in years:\n",
    "        \n",
    "        for c in countries_codes:\n",
    "            \n",
    "            data = pd.DataFrame(bop_dict)\n",
    "            \n",
    "            data[\"geo\\\\time\"] = c\n",
    "            \n",
    "            data[\"year\"] = yr\n",
    "            \n",
    "            data.loc[data[\"value\"].isna(), \"value\"] = bop_nat_flights[c]\n",
    "            \n",
    "            all_c_yr.append(data)\n",
    "            \n",
    "    bop_df = pd.concat(all_c_yr)\n",
    "    \n",
    "    units_factor = ds_transport(bop_pag, \"UNITS\")\n",
    "    \n",
    "    bop_df[\"value\"] = bop_df[\"value\"] * units_factor\n",
    "    \n",
    "    bop_df = bop_df.rename(columns = {\"value\" : ds_transport(bop_pag, \"COLNAMES\")})\n",
    "    \n",
    "    return(bop_df)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pocketbook(start_year, end_year, countries_names, file_name, file_folder, sheetname):\n",
    "    \n",
    "    \"\"\"\n",
    "    Read and filter information from an excel file containing the Eurostat Pocketbook data, filters it for the countries and years chosen\n",
    "    and fills up information gaps.\n",
    "    \n",
    "    :param start_year : first year of the period of interest.\n",
    "    :type start_year : str.\n",
    "    :param end_year : last year of the period of interest.\n",
    "    :type end_year : str.\n",
    "    :param countries_names : names of the countries of interest.\n",
    "    :type countries : list.\n",
    "    :param file_name : name of the excel file containing the information.\n",
    "    :type file_name : str.\n",
    "    :param file_fodler : path to the folder where the excel file is located.\n",
    "    :type file_folder : str.\n",
    "    :param sheetname : name of the sheet within the excel file where the information is located.\n",
    "    :type sheetname : str/int(position of the sheet beginning with 0).\n",
    "    :return : the pocketbook data filtered according to the input parameters.\n",
    "    :rtype : data frame.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    data = di.read_file(file_name, file_folder, 4, sheetname, {})\n",
    " \n",
    "    data.rename(columns = {data.columns[0] : \"geo\\\\time\"}, inplace = True)\n",
    "    \n",
    "    # There are some rows with no figures but only \"-\" in each cell. These rows will be delted. The same will be doen to the rows\n",
    "    # with cell \"geo\\\\time\" empty.\n",
    "    \n",
    "    data = data[~data[\"geo\\\\time\"].isna()]\n",
    "    \n",
    "    data = data.replace({\"-\" : np.nan, \" \" : np.nan})\n",
    "    \n",
    "    data = data.set_index(\"geo\\\\time\")\n",
    "    \n",
    "    data = data.dropna(axis = 0, how = \"all\")\n",
    "    \n",
    "    data = data.reset_index()\n",
    "    \n",
    "    data.columns = [str(c) for c in data.columns]\n",
    "    \n",
    "    # If the data for a particular year is missing it will be extrapolated out of the existing data through a linear regression.\n",
    "    \n",
    "    existing_years = [c for c in data.columns if c.isnumeric()]\n",
    "    \n",
    "    years = [str(y) for y in list(range(int(start_year), (int(end_year) + 1)))] \n",
    "    \n",
    "    years_cols = [yr for yr in years if yr in data.columns]\n",
    "    \n",
    "    def extrapolate(df, nyr):\n",
    "        df = df.dropna()\n",
    "        y = df.tolist()\n",
    " \n",
    "        if len(y)<2:\n",
    "            return(np.nan)\n",
    "        else:\n",
    "            x = df.index.astype(float)\n",
    "            f = interpolate.interp1d(x,y)\n",
    "            # The new elements are chosen to make sure lie within the range of x values.\n",
    "            new_x = [x[0], (x[0]+x[1])/2]\n",
    "            new_y = f(new_x)\n",
    "            m = np.diff(new_y)\n",
    "            b = (sum(new_y)-(m*sum(new_x)))/2\n",
    "            value = m*nyr+b\n",
    "            # The extrapolation may also produce undesired negative values.\n",
    "            if value[0]>0:\n",
    "                return(value[0])\n",
    "            else:\n",
    "                return(np.nan)\n",
    "    \n",
    "    if len(years_cols) < len(years):\n",
    "        \n",
    "        missing_years = [yr for yr in years if yr not in years_cols]\n",
    "        \n",
    "        print(\"{} not in dataset. The values will be extrapolated.\".format(missing_years))\n",
    "\n",
    "        for new_yr in missing_years:\n",
    "\n",
    "            data[new_yr] = data[existing_years].apply(lambda x: extrapolate(x, int(new_yr)),axis = 1)\n",
    "\n",
    "    # Filter by year.\n",
    "        \n",
    "    data = data[[\"geo\\\\time\"] + years]\n",
    "                                      \n",
    "    # If a country is missing from the data set, a new line will ba added for that country with the values for the selected\n",
    "    # years being the average of the corresponding values of the existing countries.\n",
    "             \n",
    "    countries_codes = check_countries(countries_names)\n",
    "    \n",
    "    absent_cc = [cc for cc in countries_codes if cc not in data[\"geo\\\\time\"].tolist()] \n",
    "    \n",
    "    data = data.set_index(\"geo\\\\time\")                              \n",
    "    \n",
    "    if len(absent_cc)>0:\n",
    "        \n",
    "        print(\"{} data is missing. The countries average will be used to fill the gap\".format(absent_cc))\n",
    "    \n",
    "        for cc in absent_cc:\n",
    "        \n",
    "            data.loc[cc] = df.mean()\n",
    "            \n",
    "    data = data.reset_index()\n",
    "                                      \n",
    "    # Fills out nan values in the years columns with the column mean.\n",
    "\n",
    "    data = data.fillna(data.mean())\n",
    "\n",
    "    # Filter by country.\n",
    "    \n",
    "    data = data[data[\"geo\\\\time\"].isin(countries_codes)]\n",
    "    \n",
    "    # Reorganize data frame.\n",
    "    \n",
    "    data = pd.melt(data, id_vars = [\"geo\\\\time\"], value_vars = years_cols)\n",
    "    \n",
    "    # Add vehicle column.\n",
    "    \n",
    "    vehicle_dict = {\"cars\" : \"Passenger_Cars\", \"rail_pkm\" : \"Trains\", \"bus_coach\" : \"Buses\", \"motorway\" : \"Buses\", \"CNLPNL\" : \"Buses\"}\n",
    "    \n",
    "    data[\"vehicle\"] = vehicle_dict[sheetname]\n",
    "    \n",
    "    # Adapt to right units.\n",
    "    \n",
    "    units_factor = ds_transport(sheetname, \"UNITS\")\n",
    "    \n",
    "    data[\"value\"] = data[\"value\"] * units_factor\n",
    "    \n",
    "    # Rename and change columns data type.\n",
    "    \n",
    "    data = data.rename(columns = {\"variable\" : \"year\", \"value\" : ds_transport(sheetname, \"COLNAMES\")})\n",
    "    \n",
    "    data[\"year\"] = data[\"year\"].astype(str)\n",
    "    \n",
    "    return(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fuel_coeff(start_year, end_year, countries_names):\n",
    "    \n",
    "    \"\"\"\n",
    "    Extract the required information and calculate the type of fuel coefficient for the provided years and countries.\n",
    "    \n",
    "    :param start_year : first year of the period of interest.\n",
    "    :type start_year : str.\n",
    "    :param end_year : last year of the period of interest.\n",
    "    :type end_year : str.\n",
    "    :param countries_names : names of the countries of interest.\n",
    "    :type countries : list.\n",
    "    :return : fuel coefficient for the provided years and countries.\n",
    "    :rtype : data frame.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    DS = \"road_eqs_carpda\"\n",
    "    \n",
    "    value_col = ds_transport(DS, \"COLNAMES\")\n",
    "    \n",
    "    data = get_mobility(start_year, end_year, countries_names, DS)\n",
    "\n",
    "    data_grp = data.groupby([\"geo\\\\time\", \"year\"])\n",
    "    \n",
    "    groups = data_grp.groups\n",
    "    \n",
    "    all_groups = []\n",
    "    \n",
    "    for g in groups:\n",
    "        \n",
    "        df = data_grp.get_group(g)\n",
    "        \n",
    "        total = df[df[\"mot_nrg\"] == \"TOTAL\"][value_col].tolist()[0]\n",
    "        \n",
    "        if math.isnan(total):\n",
    "            \n",
    "            total = df[df[\"mot_nrg\"] != \"TOTAL\"][value_col].sum()\n",
    "        \n",
    "        df.loc[:, value_col] = df.loc[:, value_col].div(total)\n",
    "        \n",
    "        all_groups.append(df)\n",
    "        \n",
    "    new_df = pd.concat(all_groups)\n",
    "    \n",
    "    return(new_df)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_eng_coeff(start_year, end_year, countries_names):\n",
    "    \n",
    "    \"\"\"\n",
    "    Extract the required information and calculate the engine displacement coefficient for the provided years and countries.\n",
    "    \n",
    "    :param start_year : first year of the period of interest.\n",
    "    :type start_year : str.\n",
    "    :param end_year : last year of the period of interest.\n",
    "    :type end_year : str.\n",
    "    :param countries_names : names of the countries of interest.\n",
    "    :type countries : list.\n",
    "    :return : engine displacement coefficient for the provided years and countries.\n",
    "    :rtype : data frame.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    DS = \"road_eqs_carmot\"\n",
    "    \n",
    "    value_col = ds_transport(DS, \"COLNAMES\")\n",
    "    \n",
    "    data = get_mobility(start_year, end_year, countries_names, DS)\n",
    "\n",
    "    data_grp = data.groupby([\"geo\\\\time\", \"year\", \"mot_nrg\"])\n",
    "    \n",
    "    groups = data_grp.groups\n",
    "    \n",
    "    all_groups = []\n",
    "    \n",
    "    for g in groups:\n",
    "        \n",
    "        df = data_grp.get_group(g)\n",
    "        \n",
    "        total = df.loc[df[\"engine\"] == \"TOTAL\"][value_col].tolist()[0]\n",
    "        \n",
    "        if math.isnan(total):\n",
    "            \n",
    "            total = df.loc[df[\"engine\"] != \"TOTAL\"][value_col].sum()\n",
    "        \n",
    "        df.loc[:, value_col] = df.loc[:, value_col].div(total)\n",
    "        \n",
    "        all_groups.append(df)\n",
    "        \n",
    "    new_df = pd.concat(all_groups)\n",
    "    \n",
    "    return(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tech_coeff(start_year, end_year, countries_names):\n",
    "    \n",
    "    \"\"\"\n",
    "    Extract the required information and calculate the technology coefficient for the provided years and countries.\n",
    "    \n",
    "    :param start_year : first year of the period of interest.\n",
    "    :type start_year : str.\n",
    "    :param end_year : last year of the period of interest.\n",
    "    :type end_year : str.\n",
    "    :param countries_names : names of the countries of interest.\n",
    "    :type countries : list.\n",
    "    :return : technology coefficient for the provided years and countries.\n",
    "    :rtype : data frame.\n",
    "    \n",
    "    \"\"\"\n",
    "    # The car definition according to the year of production. Take into account that \"range\" does not consider the last value\n",
    "    # of the interval, i.e. list(range(1980,1992)) last value is 1991.\n",
    "    \n",
    "    age_type_dict = {\"CONV\" : list(range(1980,1992)), \n",
    "                \"EU1\" : list(range(1992,1996)),\n",
    "                \"EU2\" : list(range(1996,2000)),\n",
    "                \"EU3\" : list(range(2000,2005)),\n",
    "                \"EU4\" : list(range(2005,2010)),\n",
    "                \"EU5\" : list(range(2010,2015)),\n",
    "                \"EU6\" : list(range(2015,2021)),\n",
    "               }\n",
    "    \n",
    "    DS = \"road_eqs_carage\"\n",
    "    \n",
    "    value_col = ds_transport(DS, \"COLNAMES\")\n",
    "    \n",
    "    data = get_mobility(start_year, end_year, countries_names, DS)\n",
    "    \n",
    "    data[\"year\"] = data[\"year\"].astype(int)\n",
    "    \n",
    "    def calc_age_years(x):\n",
    "        \n",
    "        ref_yr = x[\"year\"]\n",
    "        \n",
    "        if x[\"age\"] == 'Y_LT2':\n",
    "            \n",
    "            years = list(np.array(range(ref_yr-2,ref_yr)) +1)\n",
    "            \n",
    "        elif x[\"age\"] == 'Y2-5':\n",
    "            \n",
    "            years = list(np.array(range(ref_yr-5,ref_yr-2)) +1)\n",
    "            \n",
    "        elif x[\"age\"] == 'Y5-10':\n",
    "            \n",
    "            years = list(np.array(range(ref_yr-10,ref_yr-5)) +1)\n",
    "            \n",
    "        elif x[\"age\"] == 'Y10-20':\n",
    "            \n",
    "            years = list(np.array(range(ref_yr-20,ref_yr-10)) +1)\n",
    "            \n",
    "        elif x[\"age\"] == 'Y_GT10':\n",
    "            \n",
    "            years = list(np.array(range(ref_yr-20,ref_yr-10)) +1)\n",
    "            \n",
    "        elif x[\"age\"] == 'Y_GT20':\n",
    "            \n",
    "            years = list(np.array(range(1979,ref_yr-20)) +1)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            years = list(range(1980, ref_yr + 1))\n",
    "            \n",
    "        return(years)\n",
    "    \n",
    "    def calc_share(age_years, age_type):\n",
    "        \n",
    "        in_years = [yr for yr in age_years if yr in age_type_dict[age_type]]\n",
    "        \n",
    "        sh = len(in_years) / len(age_years)\n",
    "        \n",
    "        return(sh)    \n",
    "    \n",
    "    data_grp = data.groupby([\"geo\\\\time\"])\n",
    "    \n",
    "    groups = data_grp.groups\n",
    "    \n",
    "    all_groups = []\n",
    "    \n",
    "    for g in groups:\n",
    "        \n",
    "        df = data_grp.get_group(g)\n",
    "        \n",
    "        df[\"age_years\"] = df.apply(lambda x : calc_age_years(x), axis  = 1)\n",
    "        \n",
    "        for age_type in age_type_dict.keys():\n",
    "            \n",
    "            share_col = \"_\".join([age_type, \"share\"])\n",
    "            \n",
    "            df[share_col] = df[\"age_years\"].apply(lambda x : calc_share(x, age_type))\n",
    "            \n",
    "            df[age_type] = df[value_col] * df[share_col]\n",
    "             \n",
    "        final_df = df[df[\"age\"]!=\"TOTAL\"].groupby([\"geo\\\\time\", \"year\"]).sum()\n",
    "        \n",
    "        final_df.reset_index(inplace = True)\n",
    "    \n",
    "        all_groups.append(final_df)\n",
    "        \n",
    "    new_df = pd.concat(all_groups)\n",
    "    \n",
    "    # Add extra age types.\n",
    "    \n",
    "    extra_age_types = [\"CONV;EU1;EU2;EU3\", \"CONV;EU1;EU2;EU3;EU4;EU5\", \"CONV;EU1;EU2;EU3;EU4;EU5;EU6\"]\n",
    "    \n",
    "    for e_age_type in extra_age_types:\n",
    "        \n",
    "        e_age_types_list = e_age_type.split(\";\")\n",
    "        \n",
    "        new_df[e_age_type] = new_df[e_age_types_list].sum(axis = 1)\n",
    "    \n",
    "    new_df = pd.melt(new_df, id_vars = [\"geo\\\\time\", \"year\"], value_vars = list(age_type_dict.keys()) + extra_age_types)\n",
    "    \n",
    "    # Calculate the % of each age type over the total per country and year.\n",
    "    \n",
    "    total_df = new_df[new_df[\"variable\"] == \"CONV;EU1;EU2;EU3;EU4;EU5;EU6\"]\n",
    "    \n",
    "    total_df = total_df.rename(columns = {\"value\" : \"total_value\"})\n",
    "    \n",
    "    new_df = new_df.rename(columns = {\"value\" : value_col, \"variable\" : \"age_type\"})\n",
    "    \n",
    "    final_df = new_df.merge(total_df[[\"geo\\\\time\", \"year\", \"total_value\"]], how = \"left\", on = [\"geo\\\\time\", \"year\"])\n",
    "    \n",
    "    final_df[\"year\"] = final_df[\"year\"].astype(str)\n",
    "    \n",
    "    final_df[value_col] = final_df[value_col] / final_df[\"total_value\"]\n",
    "    \n",
    "    return(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mob_merge(mob_frame, col_name, start_year, end_year, countries_names, file_name, file_folder):\n",
    "    \n",
    "    \"\"\"\n",
    "    For the years and countries of interest, extracts the information from the data set/data source that should go \n",
    "    in the given column in the final data frame and merges it with the mobility frame.\n",
    "    \n",
    "    :param mob_frame : mobility frame.\n",
    "    :type mob_frame : data frame.\n",
    "    :param col_name : name of the column in the final data frame where the extracted information will be displayed.\n",
    "    :type col_name : str.\n",
    "    :param start_year : first year of the period of interest.\n",
    "    :type start_year : str.\n",
    "    :param end_year : last year of the period of interest.\n",
    "    :type end_year : str.\n",
    "    :param countries_names : names of the countries of interest.\n",
    "    :type countries : list.\n",
    "    :param file_name : the name of the file containing the information in the case the data source is POCKETBOOK.\n",
    "    :type file_name : str.\n",
    "    :param file_folder : the path to the folder containing he file with the information in the case the data source is POCKETBOOK.\n",
    "    :type file_folder : str.\n",
    "    :return : a mobility table containing the mobility frame plus one column (col_name).\n",
    "    :rtype : data frame.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    data_sets = ds_transport(\"\", \"MERGE\")[col_name]\n",
    "    \n",
    "    years = [str(yr) for yr in list(range(int(start_year), int(end_year) +1 ))]\n",
    "    \n",
    "    countries_codes = check_countries(countries_names)\n",
    "    \n",
    "    mob_frame_all = []\n",
    "    \n",
    "    for yr in years:\n",
    "        \n",
    "        for cc in countries_codes:\n",
    "            \n",
    "            mf = mob_frame.copy()\n",
    "            \n",
    "            mf[\"geo\\\\time\"] = cc\n",
    "            \n",
    "            mf[\"year\"] = yr\n",
    "            \n",
    "            mob_frame_all.append(mf)\n",
    "            \n",
    "    new_mob_frame = pd.concat(mob_frame_all)\n",
    "    \n",
    "    m_cols = list(new_mob_frame.columns)\n",
    "    \n",
    "    all_merged = []\n",
    "\n",
    "    for ds in data_sets:\n",
    "        \n",
    "        source = ds_transport(ds, \"SOURCE\")\n",
    "        \n",
    "        if source == \"ESTAT\":\n",
    "            \n",
    "            if ds == \"road_eqs_carmot\":\n",
    "                \n",
    "                data = calc_eng_coeff(start_year, end_year, countries_names)\n",
    "                \n",
    "            elif ds == \"road_eqs_carpda\":\n",
    "                \n",
    "                data = calc_fuel_coeff(start_year, end_year, countries_names)\n",
    "                \n",
    "            elif ds == \"road_eqs_carage\":\n",
    "                \n",
    "                data = calc_tech_coeff(start_year, end_year, countries_names)\n",
    "            \n",
    "            else:\n",
    "            \n",
    "                data = get_mobility(start_year, end_year, countries_names, ds)\n",
    "            \n",
    "        elif source == \"POCKETBOOK\":\n",
    "            \n",
    "            data = get_pocketbook(start_year, end_year, countries_names, file_name, file_folder, ds)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            data = get_bop(start_year, end_year, countries_names, ds)\n",
    "        \n",
    "        merge_dict = ds_transport(ds, \"SORT\")\n",
    "\n",
    "        m = new_mob_frame.merge(data, how = \"left\", left_on = list(merge_dict.keys()), right_on = list(merge_dict.values()))\n",
    "        \n",
    "        new_cols = [c for c in m.columns if c in m_cols or c == col_name]\n",
    "        \n",
    "        m = m[new_cols]\n",
    "        \n",
    "        all_merged.append(m)\n",
    "        \n",
    "    if len(all_merged) == 1:\n",
    "            \n",
    "        return(all_merged[0])\n",
    "        \n",
    "    else:\n",
    "            \n",
    "        merged = all_merged[0]\n",
    "            \n",
    "        for i in range(1, len(all_merged)):\n",
    "                \n",
    "            merged[col_name] = merged[col_name].fillna(all_merged[i][col_name])\n",
    "    \n",
    "        return(merged)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def share_columns(input_df):\n",
    "    \n",
    "    \"\"\"\n",
    "    For the columns num_vehi and trkm in the mobility table, calculates, for two different vehicle types, 2W and Trains, \n",
    "    the share of each of the different classes within each of the vehicle types.\n",
    "    \n",
    "    :param input_df : mobility table.\n",
    "    :type input_df : data frame.\n",
    "    :return : mobility table plus two new columns containing the share values.\n",
    "    :rtype : data frame.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    data_gr = input_df.groupby([\"geo\\\\time\", \"year\"])\n",
    "\n",
    "    groups = data_gr.groups\n",
    "    \n",
    "    def share_calc(x, col, total):\n",
    "        \n",
    "        if x[\"vehicle_type\"] in col:\n",
    "            \n",
    "            if col == \"2W\":\n",
    "            \n",
    "                return(x[\"num_vehi\"]/total)\n",
    "            \n",
    "            elif col == \"Trains\":\n",
    "                \n",
    "                return(x[\"trkm\"]/total)\n",
    "            \n",
    "            elif col == \"Buses_fuel\":\n",
    "                \n",
    "                return(x[\"num_vehi\"]/total)\n",
    "            \n",
    "            elif col == \"Buses_road\":\n",
    "                \n",
    "                return(x[\"mill_vehikm\"]/total)\n",
    "            \n",
    "            else: \n",
    "                \n",
    "                print(\"Non-recognized column\")\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return(np.nan)\n",
    "\n",
    "    all_groups = []\n",
    "\n",
    "\n",
    "    for g in groups:\n",
    "    \n",
    "        df = data_gr.get_group(g)\n",
    "        \n",
    "        twow_total = df[df[\"vehicle_type\"] == \"2W\"][\"num_vehi\"].sum()\n",
    "        \n",
    "        trains_total = df[df[\"vehicle_type\"] == \"Trains\"][\"trkm\"].sum()\n",
    "        \n",
    "        bus_road_total = df[df[\"vehicle_type\"] == \"Buses\"][\"mill_vehikm\"].sum()\n",
    "        \n",
    "        bus_fuel_total = df[df[\"vehicle_type\"] == \"Buses\"][\"num_vehi\"].sum()\n",
    "    \n",
    "        df[\"num_vehi_share\"] = df.apply(lambda x : share_calc(x, \"2W\", twow_total), axis = 1)\n",
    "\n",
    "        df[\"trkm_share\"] = df.apply(lambda x : share_calc(x, \"Trains\", trains_total), axis = 1)\n",
    "        \n",
    "        df[\"bus_fuel_share\"] = df.apply(lambda x : share_calc(x, \"Buses_fuel\", bus_fuel_total), axis = 1)\n",
    "\n",
    "        df[\"bus_road_share\"] = df.apply(lambda x : share_calc(x, \"Buses_road\", bus_road_total), axis = 1)\n",
    "        \n",
    "        df[df[\"vehicle_type\"]!=\"2W\"][\"num_vehi_share\"] = np.nan\n",
    "        \n",
    "        df[df[\"vehicle_type\"]!=\"Trains\"][\"trkm_share\"] = np.nan\n",
    "        \n",
    "        df[df[\"vehicle_type\"]!=\"Buses\"][\"bus_fuel_share\"] = np.nan\n",
    "        \n",
    "        df[df[\"vehicle_type\"]!=\"Buses\"][\"bus_road_share\"] = np.nan\n",
    "\n",
    "    \n",
    "        all_groups.append(df)\n",
    "    \n",
    "    new_df = pd.concat(all_groups)\n",
    "    \n",
    "    return(new_df)\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consumption(input_df):\n",
    "    \n",
    "    colnames_list = [\"num_vehi_share\", \"trkm_share\", \"bus_road_share\", \"bus_fuel_share\", \"num_p\", \"flight_km\", \"contr_pkm\", \"mill_pkm\",  \"eng_coeff\", \"tech_coeff\", \"fuel_coeff\"]\n",
    "    \n",
    "    prod_df = input_df[colnames_list]\n",
    "    \n",
    "    input_df[\"Result\"] = prod_df.product(axis  = 1)\n",
    "    \n",
    "    input_df[\"Result\"] = input_df[\"Result\"].div(input_df[\"ocp_factor\"], fill_value = 1)\n",
    "    \n",
    "    return(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobility(mob_frame, start_year, end_year, countries_names, file_name, file_folder):\n",
    "    \n",
    "    \"\"\"\n",
    "    For the years and countries of interest, extracts the information from all the data set/data source, filters it, makes\n",
    "    the required calculations and merge them with the mobility frame.\n",
    "    \n",
    "    :param mob_frame : mobility frame.\n",
    "    :type mob_frame : data frame.\n",
    "    :param start_year : first year of the period of interest.\n",
    "    :type start_year : str.\n",
    "    :param end_year : last year of the period of interest.\n",
    "    :type end_year : str.\n",
    "    :param countries_names : names of the countries of interest.\n",
    "    :type countries : list.\n",
    "    :param file_name : the name of the file containing the information in the case the data source is POCKETBOOK.\n",
    "    :type file_name : str.\n",
    "    :param file_folder : the path to the folder containing he file with the information in the case the data source is POCKETBOOK.\n",
    "    :type file_folder : str.\n",
    "    :return : a mobility table containing the mobility frame plus all the required columns.\n",
    "    :rtype : data frame.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    colnames_list = [\"num_vehi\", \"trkm\", \"num_p\", \"flight_km\", \"contr_pkm\", \"mill_pkm\", \"mill_vehikm\",  \"eng_coeff\", \"tech_coeff\", \"fuel_coeff\", \"ocp_factor\"]\n",
    "\n",
    "    mob_frame_cols = list(mob_frame.columns)\n",
    "\n",
    "    mob_frame_cols.append(\"geo\\\\time\")\n",
    "\n",
    "    mob_frame_cols.append(\"year\")\n",
    "\n",
    "    all_colnames = []\n",
    "\n",
    "    for col in colnames_list:\n",
    "    \n",
    "        print(col)\n",
    "    \n",
    "        m = mob_merge(mob_frame, col, start_year, end_year, countries_names, file_name, file_folder)\n",
    "    \n",
    "        all_colnames.append(m)\n",
    "\n",
    "    all_merged = []\n",
    "\n",
    "    all_merged.append(all_colnames[0])\n",
    "    \n",
    "    for i in range(1, len(all_colnames)):\n",
    "    \n",
    "        previous = all_merged[i-1]\n",
    "    \n",
    "        all_merged.append(previous.merge(all_colnames[i], how = \"left\", on = mob_frame_cols))\n",
    "\n",
    "    final_merged = all_merged[-1]\n",
    "    \n",
    "    final_merged_complete = share_columns(final_merged)\n",
    "    \n",
    "    # Filling the tech_coeff and eng_coeff values for the LPG car\n",
    "    \n",
    "    final_merged_complete.loc[final_merged_complete[\"type\"] == \"LPG\", \"eng_coeff\"] = 1\n",
    "    \n",
    "    final_merged_complete.loc[final_merged_complete[\"type\"] == \"LPG\", \"tech_coeff\"] = 1\n",
    "    \n",
    "    # Calculating the consumption (?)\n",
    "    \n",
    "    consumption_df = consumption(final_merged_complete)\n",
    "    \n",
    "    # Adding units.\n",
    "    \n",
    "    final_merged_complete[\"units\"] = \"VKM\"\n",
    "    \n",
    "    final_merged_complete.loc[final_merged_complete[\"code\"].isin([\"SP23\",\"SP24\",\"SP25\", \"SP26\", \"SP27\"]),\"units\"] = \"PKM\"\n",
    "    \n",
    "    return(final_merged_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
